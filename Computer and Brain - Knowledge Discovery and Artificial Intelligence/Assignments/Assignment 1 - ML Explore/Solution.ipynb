{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "ML_explore (Ashutosh Jha - 11011).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9qhWB6-RMHF"
      },
      "source": [
        "# just coz I always just do this.\n",
        "# I am sure this will be used not matter what!\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwldQ-MxRMHS"
      },
      "source": [
        "# check import sklearn\n",
        "# feel free to import whatever you need\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNVBXjDORMHb"
      },
      "source": [
        "## Task - ML Explore\n",
        "\n",
        "### Part 1 - Loading Datasets\n",
        "[**Datasets**](https://scikit-learn.org/stable/datasets/index.html)\n",
        "* Boston\n",
        "* Iris\n",
        "* Diabetes\n",
        "* Digits\n",
        "* Wine\n",
        "\n",
        "### Part 2 - Data exploration\n",
        "* Pandas description\n",
        "* Matplotlib visualisation\n",
        "* PCA\n",
        "\n",
        "### Part 3 - Data Preparation\n",
        "* [Preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)\n",
        "    * StandardScalar\n",
        "    * MinMaxScalar\n",
        "    * Normalization\n",
        "    * Discretization\n",
        "* Train test split\n",
        "\n",
        "### Part 4 - Setup models\n",
        "* [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
        "* Supervised\n",
        "    * logistic/linear regression\n",
        "    * Support vector machine\n",
        "    * Naive bayes\n",
        "    * Decision trees\n",
        "    * KNN\n",
        "    * Ensemble methods\n",
        "* Clustering (unsupervised)\n",
        "    * k means\n",
        "    * Affinity propagation\n",
        "\n",
        "### Part 5 - Training\n",
        "\n",
        "### Part 6 - Prediction\n",
        "\n",
        "### Part 7 - Evaluation\n",
        "\n",
        "**This according to me is one of the most important parts**\n",
        "* [Classification Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)\n",
        "    * Accuracy Score\n",
        "    * F1_score\n",
        "    * Confusion matrix\n",
        "    * Precision recall curve\n",
        "* [Regression Metrics](https://scikit-learn.org/stable/modules/classes.html#regression-metrics)\n",
        "    * Mean absolute error\n",
        "    * Mean squared error\n",
        "    * R2 score\n",
        "\n",
        "* [Clustering Metrics](https://scikit-learn.org/stable/modules/classes.html#clustering-metrics)\n",
        "    * Adjusted rand score\n",
        "    * V measure score\n",
        "    * Contingency matrix\n",
        "\n",
        "### Part 8 - Model Tuning\n",
        "* Manual evaluation\n",
        "* Grid search\n",
        "* Randomized search\n",
        "* Cross validation (Also an evaluation method)\n",
        "* Validation curves\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg_cX0kLXZSr"
      },
      "source": [
        "**SOLUTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1zUljjKW3Lm"
      },
      "source": [
        "from sklearn import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RZsycM1XKsS"
      },
      "source": [
        "dataset = datasets.load_wine(return_X_y = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Yk7iDVPXcG5"
      },
      "source": [
        "x = dataset.data\n",
        "y = dataset.target\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xSLfSzdX0eT"
      },
      "source": [
        "**Splitting into training**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CRNTBB1XxfM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHvlMRyIY0vW"
      },
      "source": [
        "**Feature scaling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WshTYo4iY3cj"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "std = StandardScaler()\n",
        "x_train = std.fit_transform(x_train)\n",
        "x_test = std.transform(x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xKo58XAcVXb"
      },
      "source": [
        "**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKguVimvb4gp",
        "outputId": "187bb1ba-8438-4f19-d706-cf62aa71b83a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_classifer = LogisticRegression(random_state = 0)\n",
        "lr_classifer.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcYIriVXcxOw"
      },
      "source": [
        "lr_y_pred = lr_classifer.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnFz6w9MdiMq"
      },
      "source": [
        "\n",
        "**Confusion Matrix and Accuracy Score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38SiHwYueSa8",
        "outputId": "0d0d8120-b076-402d-839b-3b22dc292da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "print(confusion_matrix(y_test, lr_y_pred))\n",
        "print(accuracy_score(y_test, lr_y_pred))\n",
        "print(f1_score(y_test, lr_y_pred, average='macro'))\n",
        "\n",
        "#The dataset is not binary therefore we use average\n",
        "print(precision_score(y_test, lr_y_pred, average = 'micro'))\n",
        "print(recall_score(y_test, lr_y_pred, average = 'micro'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[22  0  0]\n",
            " [ 0 30  1]\n",
            " [ 0  0 19]]\n",
            "0.9861111111111112\n",
            "0.9859885105786744\n",
            "0.9861111111111112\n",
            "0.9861111111111112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AwbuU5XfRJI"
      },
      "source": [
        "**K-Fold Cross Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8m20gAkfB9J",
        "outputId": "ea059a3a-b4e0-4c3d-8929-02fab18ba88c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracy = cross_val_score(estimator = lr_classifer, X = x_train, y = y_train, cv = 20)\n",
        "print(accuracy)\n",
        "print(accuracy.mean())\n",
        "print(accuracy.std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.83333333 1.         1.         1.         1.         1.\n",
            " 1.         0.8        1.         1.         1.         1.\n",
            " 1.         1.         1.         0.8        1.         1.\n",
            " 1.         1.        ]\n",
            "0.9716666666666667\n",
            "0.06772083217970012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAXhGCkrr-ZD"
      },
      "source": [
        "**Decision Trees**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl-73pr5tNZR",
        "outputId": "30be3375-c167-4b5d-8ee7-061a340cd94f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dc = DecisionTreeClassifier(random_state=0)\n",
        "dc.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFBuMtzDt0Q6"
      },
      "source": [
        "new_pred = dc.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH4ZzLqvt8O6",
        "outputId": "50d2e6d3-a041-4fd2-a2ce-9ea79177a640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "print(confusion_matrix(y_test, new_pred))\n",
        "print(accuracy_score(y_test, new_pred))\n",
        "print(f1_score(y_test, new_pred, average='macro'))\n",
        "\n",
        "#The dataset is not binary therefore we use average\n",
        "print(precision_score(y_test, new_pred, average = 'micro'))\n",
        "print(recall_score(y_test, new_pred, average = 'micro'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[21  1  0]\n",
            " [ 2 27  2]\n",
            " [ 0  0 19]]\n",
            "0.9305555555555556\n",
            "0.9328625235404897\n",
            "0.9305555555555556\n",
            "0.9305555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX6DWpoeuPUo"
      },
      "source": [
        "## Experiment !\n",
        "| No. | Name | Accuracy(in %) | F1_score | Confusion Matrix | Precision_score | Recall_curve | \n",
        "| --- | --- | --- | --- | --- | --- | --- |\n",
        "| 1 | Logistic Regression | 97.85 | 1 | [[14  0  0],[ 0 16  0],[ 0  0  6]] | 1 | 1 |\n",
        "| 2 | Decision Tress | 97.22 | 0.9777 | [[14  0  0], [ 1 15  0], [ 0  0  6]] | 0.972 | 0.972 |\n",
        "\n",
        "\n",
        "## Experimenting with Spliting the data\n",
        "| No. | test_size | Accuracy(in %) | F1_score | Confusion Matrix | Precision_score | Recall_curve | \n",
        "| --- | --- | --- | --- | --- | --- | --- |\n",
        "| 1 | 0.2 | 97.85 | 1 | [[14  0  0] , [ 0 16  0] , [ 0  0  6]] | 1 | 1 |\n",
        "| 2 | 0.22 | 97.857 | 1 | [[14  0  0], [ 0 18  0] , [ 0  0  8]] | 1 | 1 |\n",
        "| 3 | 0.3 | 95.47 | 1 | [[19  0  0] , [ 0 22  0] , [ 0  0 13]] | 1 | 1 |\n",
        "| 4 | 0.4 | 97.1666 | 0.9859885105786744 |[[22  0  0] , [ 0 30  1] , [ 0  0 19]]] | 0.9861111111111112 | 0.9861111111111112 |\n"
      ]
    }
  ]
}